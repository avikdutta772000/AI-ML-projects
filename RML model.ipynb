{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b5cee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,initializers,constraints\n",
    "import time\n",
    "import math\n",
    "import subprocess\n",
    "import string\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e22a5d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file = open('Features/stopwords.txt','r')\n",
    "stopwords = stopwords_file.read().split('\\n')\n",
    "\n",
    "max_binary_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a82aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_query_doc(index,column_names):\n",
    "    quer_doc_loc = 'Features/feature/{}.txt'.format(index)\n",
    "    query_doc=pd.read_csv(quer_doc_loc, sep=\" \", skiprows=1,names=column_names) # only place where num_of_docs is required\n",
    "    query_doc[column_names[1:]]=query_doc[column_names[1:]].fillna(query_doc.mode().iloc[0])\n",
    "    query_doc=query_doc.replace('-âˆž',0)\n",
    "    query_doc[column_names[1:]]=query_doc[column_names[1:]].astype(float)\n",
    "    query_doc = query_doc[~query_doc['word'].isin(stopwords)]\n",
    "    query_doc = query_doc[query_doc['word'].isin(words.words())]\n",
    "    return query_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fbd15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_len_dectobin(tensor):\n",
    "    global max_binary_len\n",
    "    final_tensor = []\n",
    "    for num in tensor:\n",
    "        c=0\n",
    "        x=[]\n",
    "        while num>0:\n",
    "            x=[num%2]+x\n",
    "            num=tf.constant(int(num/2))\n",
    "            c+=1\n",
    "        x=np.array(x)-0.5\n",
    "        x = np.pad(x,(max_binary_len-c,0),'constant')\n",
    "        final_tensor = final_tensor+[tf.convert_to_tensor(x,dtype=tf.float32)]\n",
    "    return tf.convert_to_tensor(final_tensor,dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f1f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: decimal_to_binary(f) -- shape=(num of bits,1)  \n",
    "class Phi_Block(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Phi_Block,self).__init__()\n",
    "    \n",
    "    def build(self,inputs_shape):\n",
    "        self.w_phi=self.add_weight(name='w_phi',\n",
    "                                   shape=(inputs_shape[-1],),\n",
    "                                   initializer=initializers.RandomUniform(minval=0.1, maxval=1.), # random uniform initialised between 0 and 2\n",
    "                                   #constraint=constraints.non_neg,\n",
    "                                   trainable=True,\n",
    "                                   )\n",
    "        self.b_phi=self.add_weight(name='b_phi',\n",
    "                                   shape=(1,),\n",
    "                                   initializer=initializers.RandomUniform(minval=0.1, maxval=1.),\n",
    "                                   trainable=True,\n",
    "                                   )\n",
    "        \n",
    "        \n",
    "    def call(self,input_tensor): # shape of input_tensor : ( number_of_words , max_binary_len )\n",
    "        w_temp=tf.math.cumsum(self.w_phi,axis=0,reverse=True)\n",
    "        return keras.activations.tanh(tf.math.reduce_sum(tf.multiply(input_tensor,w_temp),axis=-1)+self.b_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b16488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Net_Block(layers.Layer):\n",
    "    def __init__(self,num_of_features,agg_dim):\n",
    "        super(Policy_Net_Block,self).__init__()\n",
    "        self.num_of_features=num_of_features\n",
    "        self.agg_dim=agg_dim\n",
    "        self.phi_block=[]\n",
    "        for i in range(num_of_features):\n",
    "            self.phi_block=self.phi_block+[Phi_Block()]\n",
    "\n",
    "    def call(self,input_tensor): # input tensor is the word embedding [f1,f2,....,fl] --> shape: (number_of_words,l=num_of_features)\n",
    "        temp=[]\n",
    "        for i in range(self.num_of_features):\n",
    "#            temp=temp+[self.phi_block[i](\n",
    "#                tf.cast(tf.reverse(tf.math.floormod(tf.bitwise.right_shift(\n",
    "#                    tf.expand_dims(tf.cast(input_tensor[:,i],dtype=tf.int32),1), tf.range(8)), 2),[-1]),\n",
    "#                        dtype=tf.float32)-0.5\n",
    "#            )]\n",
    "            \n",
    "            temp = temp + [self.phi_block[i](fixed_len_dectobin(tf.cast(input_tensor[:,i],dtype=tf.int32)))]\n",
    "        temp_tensor=tf.transpose(tf.convert_to_tensor(temp,dtype=tf.float32))\n",
    "        agg_out=layers.Dense(self.agg_dim)(temp_tensor)\n",
    "        return agg_out # output of shape : (number_of_words,num_of_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ce0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Network_Model(keras.Model):\n",
    "    def __init__(self,agg_dim=8): # default agg_dim is set here\n",
    "        super(Policy_Network_Model,self).__init__()\n",
    "        self.agg_dim=agg_dim\n",
    "        \n",
    "    def build(self,input_shape): # input_shape = (number_of_words,num_of_docs,num_of_features)\n",
    "        self.num_feat=input_shape[-1]\n",
    "        self.num_doc=input_shape[-2]\n",
    "        self.conc=[]\n",
    "        for i in range(self.num_doc):\n",
    "            self.conc=self.conc+[Policy_Net_Block(self.num_feat,self.agg_dim)]\n",
    "        self.comp=layers.Dense(1)\n",
    "        \n",
    "    \n",
    "    def call(self,input_tensor,training=False):\n",
    "        comp_inp=[] # contains list of d dimensional vectors of size |F|\n",
    "        temp=[]\n",
    "        for i in range(self.num_doc):\n",
    "            comp_inp=comp_inp+[self.conc[i](input_tensor[:,i,:])]\n",
    "        temp=tf.concat(comp_inp,axis = -1)\n",
    "        out=self.comp(temp)\n",
    "        return out # output shape : (number_of_words,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Hyper parameters\n",
    "# 1) learning rate of Adam optimiser - {1e-3, 5e-4, 1e-4}\n",
    "# 2) number of feedback terms in the reformulised query - {5, 10, 15, 20, 25}\n",
    "# 3) feedback coefficient - {0.0, 0.2, ...., 1.0}\n",
    "\n",
    "# 5-fold cross validation is performed\n",
    "# top 1000 documents are retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a068d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop the above functions as class functions\n",
    "class RML_model:\n",
    "    \n",
    "    def __init__(self,K):\n",
    "        self.model=Policy_Network_Model()\n",
    "        self.prev_eval=0.0\n",
    "        self.K=K # number of samples extracted\n",
    "    \n",
    "    def data_preprocessing(self,index):\n",
    "        #extract the docs for the given query index 'ind'\n",
    "        F = []\n",
    "        q_df=self.query_doc_dict[index] # q_df stores the dataframe for docs retrieved by each query\n",
    "        num_of_docs=int((len(q_df.columns)-3)/2)\n",
    "        for i in range(q_df.shape[0]):\n",
    "            # F should be 2D matrix with shape (num_of_docs,num_of_features)\n",
    "            F_w=[]\n",
    "            s=q_df.iloc[i]\n",
    "            for j in range(1,num_of_docs+1):\n",
    "                # The number and type of features is hard coded in this section\n",
    "                F_w.append([s['tf{}'.format(j)],s['idf'],s['dl{}'.format(j)],s['df']])\n",
    "            # F_w has been obtaied for a given word\n",
    "            F = F + [F_w]\n",
    "        F=tf.convert_to_tensor(F)\n",
    "        return F\n",
    "    \n",
    "    def prob_dist_query(self,F):  # ---> R(Q,F;C,Omega)   F has shape : (num_of_words,num_of_docs,num_of_features)\n",
    "        R=self.model(F,training=True)\n",
    "        R = tf.keras.activations.softmax(R,axis=0)\n",
    "        return R # returns array of softmax p(w/Q) -- shape(num_of_words,1)\n",
    "    \n",
    "    def sampling_function(self,R): # shape of R : (number_of_words,1)\n",
    "        \n",
    "        samples=tf.convert_to_tensor(np.random.choice(np.arange(len(self.vocabulary)),\n",
    "                                                      size=(self.K,),replace=False,p=R[:,0].numpy()))\n",
    "        #samples = tf.random.categorical(tf.math.log(tf.transpose(R).numpy()),self.K)[0]\n",
    "        R_dash = tf.gather(params = R[:,0], indices = samples)\n",
    "        R_dash=R_dash/tf.math.reduce_sum(R_dash)\n",
    "        return samples,R_dash # returns (tensor,tensor)\n",
    "    \n",
    "    def sampling_test_function(self,R):\n",
    "        samples = tf.math.top_k(R[:,0],k=self.K)\n",
    "        R_dash = samples.values\n",
    "        R_dash = R_dash/tf.math.reduce_sum(R_dash)\n",
    "        return samples.indices,R_dash\n",
    "        \n",
    "    def prob_MLE_fn(self,q,samples):\n",
    "        R_MLE=tf.convert_to_tensor([q.count(self.vocabulary[i]) for i in samples.numpy()],dtype=tf.float32)\n",
    "        return R_MLE/len(q.split()) # returns tensor\n",
    "\n",
    "    def interpolation_function(self,R_MLE,R_dash,alpha=0.5): # alpha is Hyperparamter (importance of word in the original query)\n",
    "        R_cap=alpha*R_MLE+(1-alpha)*R_dash\n",
    "        return R_cap # returns tensor   \n",
    "    \n",
    "    def retrieval(self, index, query, rf_query):\n",
    "        filename = \"query/query_ti\"\n",
    "        xml_file = open(filename, \"w\", encoding='utf8')\n",
    "        n = xml_file.write(rf_query)\n",
    "        xml_file.close()\n",
    "    \n",
    "        #running indri query\n",
    "        indrirunquery_command =  '/home/ir-group/indri-5.12/runquery/IndriRunQuery'\n",
    "        result = subprocess.Popen([indrirunquery_command, filename],\n",
    "                                  stdout=subprocess.PIPE,\n",
    "                                  stderr=subprocess.STDOUT)\n",
    "        stdout, stderr = result.communicate()\n",
    "        \n",
    "        res_file = \"query/query_rq\"\n",
    "        file1 = open(res_file, \"wb\")\n",
    "        n1 = file1.write(stdout)\n",
    "        file1.close()\n",
    "        \n",
    "        #performing TREC_eval\n",
    "        indritrec_command =  '/home/ir-group/indri-5.12/trec_eval.9.0/trec_eval'\n",
    "        trec_qrel = '/home/ir-group/indri-5.12/trec_eval.9.0/678_qrel'\n",
    "        result1 = subprocess.Popen([indritrec_command, trec_qrel, res_file],\n",
    "                                  stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        stdout, stderr = result1.communicate()\n",
    "        \n",
    "        #saving MAP results\n",
    "        map_file = \"query/query_MAP\"\n",
    "        file2 = open(map_file, \"wb\")\n",
    "        n2 = file2.write(stdout)\n",
    "        file2.close()\n",
    "\n",
    "        #returning the MAP result for a query\n",
    "        file = open('query/query_MAP')\n",
    "        content = file.readlines()\n",
    "        #print(content)\n",
    "        split_l = content[5].split(\"\\t\")\n",
    "        print(\"MAP value: \", split_l[2])\n",
    "        MAP = split_l[2]\n",
    "        return MAP\n",
    "\n",
    "    def query_reformulation(self, word_sample_dict, index, query):\n",
    "        index_filepath = \"/home/ir-group/indri-5.12/trec678.index/\"\n",
    "        preamble_string = \"<parameters>\\n<index>\"+index_filepath+\"</index>\\n<runID>RML</runID>\\n<trecFormat>true</trecFormat>\\n<rule>method:dirichlet;mu:1500</rule>\\n<count>10</count>\\n<query>\\n<number>\" + str(index) + \"</number>\\n<text>\"\n",
    "        end_string = \"</text>\\n</query>\\n</parameters>\"\n",
    "        expansion = \"\"\n",
    "        ifac = 0.75\n",
    "        table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "        for key, value in word_sample_dict.items():\n",
    "#            print(key, \"and\", value)\n",
    "            expansion = expansion + str(value) + \" \" + key + \" \"\n",
    "            # Removing punctuations as Indri doesnt support these characters\n",
    "            term = expansion.translate(table) #removing punctuations\n",
    "            \n",
    "        reformulation = \"#weight( \" + str(ifac) + \" #combine(\" + query + \") \" + str(1-ifac) + \" #combine( \" + expansion + \"))\"\n",
    "        reformulated_query = preamble_string + \" \" + reformulation + \" \" + end_string\n",
    "        #print(reformulated_query)\n",
    "        return reformulated_query\n",
    "    \n",
    "    def eval_fn(self, word_sample_dict, index, query): # takes input the dictionary of size self.K which maps the word with its weight\n",
    "        \n",
    "        rf_query = self.query_reformulation(word_sample_dict, index, query)\n",
    "        MAP = self.retrieval(index, query, rf_query)\n",
    "        #print(\"MAP form eval\", MAP, \" \", type(MAP))\n",
    "        return tf.cast(float(MAP),dtype=tf.float32)\n",
    "            \n",
    "    def reward_fn(self,word_sample_dict, index, query):  # doubt regarding the eval(Q,t) - eval(Q,t-1), the use of prev_eval ??\n",
    "        t=self.eval_fn(word_sample_dict, index, query)\n",
    "        reward=t-self.prev_eval\n",
    "        self.prev_eval=t\n",
    "        return reward\n",
    "    \n",
    "    def cross_entropy_loss(self,R_dash,R,word_sample):\n",
    "        #R_temp=tf.convert_to_tensor([np.log(R[:,0].numpy()[i]) for i in word_sample.numpy()],dtype=tf.float32)\n",
    "        R_temp = tf.gather(params=tf.math.log(R[:,0]),indices = word_sample.numpy())\n",
    "        return tf.math.reduce_sum([i[0]*i[1] for i in zip(R_dash,R_temp)])\n",
    "    \n",
    "    def compute_loss_fn(self,X_batch): # X_batch is the dataframe containing 'index' and 'query' column for a given batch_size\n",
    "        L=tf.constant(0.,dtype=tf.float32)\n",
    "        for i in range(X_batch.shape[0]):\n",
    "            index=int(X_batch.iloc[i]['index'])\n",
    "            query = str(X_batch.iloc[i]['query'])\n",
    "            print('----------------- Running query {} and {} -----------------'.format(index, query))\n",
    "            self.vocabulary=self.query_doc_dict[index]['word'].values # stores words used in the top 'num_of_docs' retrieved by a single query\n",
    "            F = self.data_preprocessing(index)\n",
    "            R=self.prob_dist_query(F)\n",
    "            word_sample,R_dash=self.sampling_function(R)\n",
    "            R_MLE=self.prob_MLE_fn(query,word_sample)\n",
    "            R_cap=self.interpolation_function(R_MLE,R_dash,alpha=0.6) \n",
    "            word_sample_dict = dict(zip([self.vocabulary[i] for i in word_sample],R_cap.numpy()))\n",
    "            print(\"-> {}\".format(word_sample_dict))\n",
    "            L=L-self.reward_fn(word_sample_dict, index, query)*self.cross_entropy_loss(R_dash,R,word_sample)\n",
    "        L = tf.convert_to_tensor(L,dtype=tf.float32)\n",
    "        return L\n",
    "    def train(self,query_df,query_doc_dict,epochs=10,batch_size=16):  # takes input as the queries and the documents retrieved by each query as a dict\n",
    "        # query_df is the dataframe containing 'index' and 'query' column\n",
    "        num_of_queries=query_df.shape[0] \n",
    "        self.query_doc_dict=query_doc_dict\n",
    "        num_epochs=epochs\n",
    "        optimizer=keras.optimizers.Adam(learning_rate = 0.01)\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Start of training epoch : {}'.format(epoch))\n",
    "            for i in range(int(num_of_queries/batch_size)):     \n",
    "                X_batch=query_df.iloc[i*batch_size:(i+1)*batch_size] # X_batch is a dataframe with 'index' and 'query' column\n",
    "                with tf.GradientTape() as tape:\n",
    "                    loss = self.compute_loss_fn(X_batch)\n",
    "                    print(\"Loss for epoch={} and batch={} : {}\".format(epoch,i+1,loss))   \n",
    "                gradients=tape.gradient(loss,self.model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "                \n",
    "            if num_of_queries%batch_size!=0:\n",
    "                X_batch=query_df.iloc[int(num_of_queries/batch_size)*batch_size:]\n",
    "                with tf.GradientTape() as tape:\n",
    "                    loss=self.compute_loss_fn(X_batch)\n",
    "                    print(\"Loss for epoch={} and batch=rem : {}\".format(epoch,loss))   \n",
    "                gradients=tape.gradient(loss,self.model.trainable_weights)\n",
    "                optimizer.apply_gradients(zip(gradients,self.model.trainable_weights))\n",
    "        \n",
    "    def test(self,query_df,query_doc_dict):\n",
    "        print('Testing the model : ')\n",
    "        num_of_queries = query_df.shape[0]\n",
    "        self.query_doc_dict = query_doc_dict\n",
    "        map_arr = []\n",
    "        for i in range(query_df.shape[0]):\n",
    "            query = query_df.iloc[i]['query']\n",
    "            index = query_df.iloc[i]['index']\n",
    "            self.vocabulary=self.query_doc_dict[index]['word'].values\n",
    "            F = self.data_preprocessing(index)\n",
    "            R = self.prob_dist_query(F)\n",
    "            word_sample, R_dash = self.sampling_test_function(R)\n",
    "            R_MLE=self.prob_MLE_fn(query,word_sample)\n",
    "            R_cap=self.interpolation_function(R_MLE,R_dash,alpha=0.6)\n",
    "            word_sample_dict = dict(zip([self.vocabulary[i] for i in word_sample],R_cap.numpy()))\n",
    "            print('query : {}'.format(query))\n",
    "            print(\"Reformalised query terms -> {}\".format(word_sample_dict))\n",
    "            MAP = (self.eval_fn(word_sample_dict, index, query)).numpy()\n",
    "            map_arr = map_arr + [MAP]\n",
    "        return map_arr     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9159bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ir-group/venvp3/lib/python3.6/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "num_of_docs=10 # change this if number of documents retrieved by a query changes\n",
    "num_of_features=4\n",
    "agg_dim=int(np.sqrt(num_of_features)) # Hyperparameter\n",
    "\n",
    "# data preprocessing for query file\n",
    "quer_df_loc = 'Features/678-topics.txt' \n",
    "query_df=pd.read_csv(quer_df_loc,sep='=>',names=['index','query']) \n",
    "column_names=['word']\n",
    "column_names=column_names+['tf{}'.format(i) for i in range(1,num_of_docs+1)]\n",
    "column_names=column_names+['idf']\n",
    "column_names=column_names+['dl{}'.format(i) for i in range(1,num_of_docs+1)]\n",
    "column_names=column_names+['df']\n",
    "\n",
    "# temporary\n",
    "query_df = query_df[(query_df['index']!=312) & (query_df['index']!=348) & (query_df['index']!=424)]\n",
    "# temporary\n",
    "\n",
    "# list of dataframes for the vocab and feature of each word in a given query\n",
    "ret_docs=[ret_query_doc(index,column_names) for index in query_df['index'].values ]\n",
    "query_doc_dict={query_df.iloc[i]['index']:ret_docs[i] for i in range(len(ret_docs))}\n",
    "#print(max([query_doc_dict[i].max().iloc[1:].max() for i in query_df['index'].values]))\n",
    "\n",
    "# train-test split\n",
    "train_test_split_ratio = 0.9\n",
    "train_query_df = query_df.iloc[:int(train_test_split_ratio*query_df.shape[0])]\n",
    "test_query_df = query_df.iloc[int(train_test_split_ratio*query_df.shape[0]):]\n",
    "train_doc_dict = {query_df.iloc[i]['index']:ret_docs[i] for i in range(int(len(ret_docs)*train_test_split_ratio))}\n",
    "test_doc_dict = {query_df.iloc[i]['index']:ret_docs[i] for i in range(int(len(ret_docs)*train_test_split_ratio),len(ret_docs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99371789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of training epoch : 0\n",
      "----------------- Running query 301 and international organized crime -----------------\n",
      "-> {'modern': 0.11157203, 'inasmuch': 0.09781163, 'inflation': 0.091674484, 'type': 0.09894185}\n",
      "MAP value:  0.0046\n",
      "\n",
      "----------------- Running query 302 and poliomyelitis post polio -----------------\n",
      "-> {'unabashedly': 0.09747263, 'basic': 0.10538318, 'saying': 0.100855365, 'poetry': 0.09628884}\n",
      "MAP value:  0.0817\n",
      "\n",
      "----------------- Running query 303 and hubble telescope achievements -----------------\n",
      "-> {'isolated': 0.095652215, 'simply': 0.11091007, 'shelter': 0.09195216, 'ability': 0.10148557}\n",
      "MAP value:  0.1000\n",
      "\n",
      "----------------- Running query 304 and endangered species mammals -----------------\n",
      "-> {'avenue': 0.105154745, 'urial': 0.10382145, 'infrequency': 0.101156905, 'spring': 0.08986693}\n",
      "MAP value:  0.0083\n",
      "\n",
      "----------------- Running query 305 and most dangerous vehicles -----------------\n",
      "-> {'shorter': 0.099341944, 'remember': 0.099328585, 'contact': 0.0977655, 'guidance': 0.10356396}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 306 and african civilian deaths -----------------\n",
      "-> {'speaking': 0.09890082, 'pension': 0.09890082, 'mistakenly': 0.10329755, 'female': 0.09890082}\n",
      "MAP value:  0.0047\n",
      "\n",
      "----------------- Running query 307 and new hydroelectric projects -----------------\n",
      "-> {'moment': 0.10095216, 'attention': 0.09781758, 'view': 0.10329018, 'excessive': 0.09794008}\n",
      "MAP value:  0.0288\n",
      "\n",
      "----------------- Running query 308 and implant dentistry -----------------\n",
      "-> {'harness': 0.10163865, 'assistant': 0.09976146, 'discouraging': 0.10163865, 'history': 0.09696124}\n",
      "MAP value:  0.5000\n",
      "\n",
      "----------------- Running query 309 and rap and crime -----------------\n",
      "-> {'south': 0.10177926, 'burning': 0.1005005, 'nine': 0.0919137, 'purple': 0.10580657}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 310 and radio waves and brain cancer -----------------\n",
      "-> {'lucrative': 0.10092378, 'assigned': 0.11117478, 'forgiving': 0.11344742, 'computer': 0.07445403}\n",
      "MAP value:  0.1077\n",
      "\n",
      "----------------- Running query 311 and industrial espionage -----------------\n",
      "-> {'established': 0.09511346, 'employment': 0.101829164, 'apart': 0.09674108, 'considered': 0.10631632}\n",
      "MAP value:  0.0448\n",
      "\n",
      "----------------- Running query 313 and magnetic levitation maglev -----------------\n",
      "-> {'caution': 0.10215115, 'conservation': 0.09985244, 'theoretically': 0.09837469, 'conglomerate': 0.099621736}\n",
      "MAP value:  0.1075\n",
      "\n",
      "----------------- Running query 314 and marine vegetation -----------------\n",
      "-> {'trash': 0.098896764, 'radiometer': 0.10383117, 'hepatic': 0.09951347, 'bought': 0.097758606}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 315 and unexplained highway accidents -----------------\n",
      "-> {'engineering': 0.105513945, 'themselves': 0.09319117, 'heavy': 0.094405785, 'pair': 0.10688914}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 316 and polygamy polyandry polygyny -----------------\n",
      "-> {'stratagem': 0.099403396, 'detail': 0.100468986, 'effects': 0.100063816, 'peculiarly': 0.100063816}\n",
      "MAP value:  0.1313\n",
      "\n",
      "----------------- Running query 317 and unsolicited faxes -----------------\n",
      "-> {'message': 0.10799002, 'convenient': 0.09441216, 'control': 0.093536526, 'unveiled': 0.104061306}\n",
      "MAP value:  0.0873\n",
      "\n",
      "----------------- Running query 318 and best retirement country -----------------\n",
      "-> {'tactics': 0.09965814, 'surprise': 0.100403525, 'background': 0.1002802, 'china': 0.09965814}\n",
      "MAP value:  0.0047\n",
      "\n",
      "----------------- Running query 319 and new fuel sources -----------------\n",
      "-> {'deep': 0.09536071, 'renovation': 0.095347874, 'northern': 0.09589007, 'gasoline': 0.11340135}\n",
      "MAP value:  0.0154\n",
      "\n",
      "----------------- Running query 320 and undersea fiber optic cable -----------------\n",
      "-> {'landing': 0.10697164, 'compound': 0.09874014, 'reason': 0.10055498, 'optically': 0.09373327}\n",
      "MAP value:  0.0278\n",
      "\n",
      "----------------- Running query 321 and women in parliaments -----------------\n",
      "-> {'afraid': 0.10215254, 'fellow': 0.093296096, 'reiterated': 0.103882544, 'building': 0.10066886}\n",
      "MAP value:  0.0153\n",
      "\n",
      "----------------- Running query 322 and international art crime -----------------\n",
      "-> {'drink': 0.1108039, 'doing': 0.080969445, 'snuff': 0.10371814, 'triumphal': 0.1045085}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 323 and literary journalistic plagiarism -----------------\n",
      "-> {'moderation': 0.10140969, 'curtailed': 0.09953011, 'frequent': 0.09953011, 'rigid': 0.09953011}\n",
      "MAP value:  0.0630\n",
      "\n",
      "----------------- Running query 324 and argentine british relations -----------------\n",
      "-> {'province': 0.097545385, 'crisis': 0.09117869, 'south': 0.11355811, 'vicar': 0.097717814}\n",
      "MAP value:  0.0351\n",
      "\n",
      "----------------- Running query 325 and cult lifestyles -----------------\n",
      "-> {'tone': 0.0911432, 'triple': 0.10890861, 'propaganda': 0.09543989, 'childhood': 0.10450833}\n",
      "MAP value:  0.0176\n",
      "\n",
      "----------------- Running query 326 and ferry sinkings -----------------\n",
      "-> {'responsibility': 0.09957194, 'seeking': 0.10441285, 'unfair': 0.099404015, 'parliament': 0.09661121}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 327 and modern slavery -----------------\n",
      "-> {'mahatma': 0.092829496, 'void': 0.10124612, 'flesh': 0.10124612, 'singing': 0.10467825}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 328 and pope beatifications -----------------\n",
      "-> {'capitalist': 0.09928985, 'woman': 0.10623602, 'scarcity': 0.10262074, 'example': 0.09185338}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 329 and mexican air pollution -----------------\n",
      "-> {'clean': 0.03273065, 'university': 0.094905645, 'leading': 0.09951653, 'percent': 0.17284717}\n",
      "MAP value:  0.0857\n",
      "\n",
      "----------------- Running query 330 and iran iraq cooperation -----------------\n",
      "-> {'draft': 0.099228315, 'amply': 0.10476005, 'consistent': 0.09645433, 'engaged': 0.09955732}\n",
      "MAP value:  0.0097\n",
      "\n",
      "----------------- Running query 331 and world bank criticism -----------------\n",
      "-> {'affected': 0.100513935, 'yesterday': 0.09858482, 'found': 0.10398709, 'facing': 0.09691417}\n",
      "MAP value:  0.0469\n",
      "\n",
      "----------------- Running query 332 and income tax evasion -----------------\n",
      "-> {'phenomenon': 0.086429425, 'soviet': 0.10445346, 'dissatisfied': 0.104558565, 'rubber': 0.104558565}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 333 and antibiotics bacteria disease -----------------\n",
      "-> {'arrest': 0.09975622, 'vaccination': 0.09600414, 'form': 0.11558445, 'farm': 0.088655226}\n",
      "MAP value:  0.0798\n",
      "\n",
      "----------------- Running query 334 and export controls cryptography -----------------\n",
      "-> {'challenge': 0.12127947, 'scrounging': 0.09255838, 'report': 0.09360378, 'reluctantly': 0.09255838}\n",
      "MAP value:  0.2333\n",
      "\n",
      "----------------- Running query 335 and adoptive biological parents -----------------\n",
      "-> {'hug': 0.08655972, 'recreation': 0.092203595, 'grieved': 0.08655972, 'placement': 0.13467698}\n",
      "MAP value:  0.0878\n",
      "\n",
      "----------------- Running query 336 and black bear attacks -----------------\n",
      "-> {'sharp': 0.106942, 'representative': 0.095104486, 'reposition': 0.09828777, 'gain': 0.09966577}\n",
      "MAP value:  0.0833\n",
      "\n",
      "----------------- Running query 337 and viral hepatitis -----------------\n",
      "-> {'training': 0.10414314, 'viral': 0.40614527, 'farm': 0.084995285, 'millions': 0.104716316}\n",
      "MAP value:  0.0225\n",
      "\n",
      "----------------- Running query 338 and risk of aspirin -----------------\n",
      "-> {'chest': 0.08429164, 'helpful': 0.09232354, 'half': 0.12588109, 'overview': 0.09750372}\n",
      "MAP value:  0.5000\n",
      "\n",
      "----------------- Running query 339 and alzheimer drug treatment -----------------\n",
      "-> {'worst': 0.10356003, 'based': 0.09715752, 'diagnosis': 0.10172444, 'six': 0.097558014}\n",
      "MAP value:  0.1000\n",
      "\n",
      "----------------- Running query 340 and land mine ban -----------------\n",
      "-> {'project': 0.090965755, 'elemental': 0.10301142, 'determine': 0.10301142, 'exploration': 0.10301142}\n",
      "MAP value:  0.0348\n",
      "\n",
      "----------------- Running query 341 and airport security -----------------\n",
      "-> {'exposed': 0.10100209, 'qualify': 0.09879743, 'sabotage': 0.09975435, 'scanning': 0.10044614}\n",
      "MAP value:  0.1026\n",
      "\n",
      "----------------- Running query 342 and diplomatic expulsion -----------------\n",
      "-> {'observer': 0.099329956, 'grim': 0.099867865, 'objective': 0.099329956, 'absolutely': 0.1014722}\n",
      "MAP value:  0.0236\n",
      "\n",
      "----------------- Running query 343 and police deaths -----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> {'township': 0.10149536, 'heavy': 0.10798068, 'brother': 0.08826521, 'rifle': 0.10225874}\n",
      "MAP value:  0.0026\n",
      "\n",
      "----------------- Running query 344 and abuses of e mail -----------------\n",
      "-> {'control': 0.104587235, 'governance': 0.09956759, 'instance': 0.09884963, 'principal': 0.096995495}\n",
      "MAP value:  0.0400\n",
      "\n",
      "----------------- Running query 345 and overseas tobacco sales -----------------\n",
      "-> {'logic': 0.10428723, 'p': 0.072766446, 'dump': 0.1281281, 'downturn': 0.09481823}\n",
      "MAP value:  0.0220\n",
      "\n",
      "----------------- Running query 346 and educational standards -----------------\n",
      "-> {'careful': 0.094363205, 'education': 0.4188356, 'variety': 0.09292014, 'preclude': 0.09388106}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 347 and wildlife extinction -----------------\n",
      "-> {'autonomous': 0.09501869, 'impact': 0.10517191, 'elimination': 0.10182738, 'plant': 0.09798203}\n",
      "MAP value:  0.0007\n",
      "\n",
      "----------------- Running query 349 and metabolism -----------------\n",
      "-> {'microbiological': 0.10251216, 'clearance': 0.09825312, 'expressed': 0.10251216, 'data': 0.09672256}\n",
      "MAP value:  0.0358\n",
      "\n",
      "----------------- Running query 350 and health and computer terminals -----------------\n",
      "-> {'natural': 0.11122016, 'simultaneously': 0.08844545, 'showpiece': 0.08929629, 'degree': 0.1110381}\n",
      "MAP value:  0.0536\n",
      "\n",
      "----------------- Running query 351 and falkland petroleum exploration -----------------\n",
      "-> {'agreement': 0.10547453, 'stop': 0.09817515, 'weekly': 0.09817515, 'marsh': 0.09817515}\n",
      "MAP value:  0.2083\n",
      "\n",
      "----------------- Running query 352 and british chunnel impact -----------------\n",
      "-> {'excellent': 0.10177853, 'public': 0.10955202, 'protocol': 0.10179573, 'include': 0.0868737}\n",
      "MAP value:  0.0195\n",
      "\n",
      "----------------- Running query 353 and antarctica exploration -----------------\n",
      "-> {'san': 0.105443574, 'exceptionally': 0.099757105, 'pendulum': 0.105918325, 'wildlife': 0.08888101}\n",
      "MAP value:  0.0492\n",
      "\n",
      "----------------- Running query 354 and journalist risks -----------------\n",
      "-> {'react': 0.1001723, 'involvement': 0.10189722, 'identify': 0.09896525, 'newsworthiness': 0.09896525}\n",
      "MAP value:  0.0007\n",
      "\n",
      "----------------- Running query 355 and ocean remote sensing -----------------\n",
      "-> {'freshness': 0.10338453, 'probably': 0.09429988, 'bad': 0.10338453, 'phase': 0.09893109}\n",
      "MAP value:  0.0796\n",
      "\n",
      "----------------- Running query 356 and postmenopausal estrogen britain -----------------\n",
      "-> {'feeling': 0.099400856, 'try': 0.10152643, 'oil': 0.09948185, 'grown': 0.09959083}\n",
      "MAP value:  0.0059\n",
      "\n",
      "----------------- Running query 357 and territorial waters dispute -----------------\n",
      "-> {'un': 0.098012485, 'official': 0.11489407, 'concept': 0.09537198, 'previously': 0.091721475}\n",
      "MAP value:  0.0326\n",
      "\n",
      "----------------- Running query 358 and blood alcohol fatalities -----------------\n",
      "-> {'exactly': 0.093450814, 'county': 0.10963891, 'involve': 0.1058942, 'fourth': 0.09101611}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 359 and mutual fund predictors -----------------\n",
      "-> {'movie': 0.10112362, 'mental': 0.09483164, 'ma': 0.10921308, 'elevated': 0.09483164}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 360 and drug legalization benefits -----------------\n",
      "-> {'speculation': 0.096660376, 'augment': 0.09652605, 'enforcement': 0.1018868, 'fall': 0.10492678}\n",
      "MAP value:  0.0582\n",
      "\n",
      "----------------- Running query 361 and clothing sweatshops -----------------\n",
      "-> {'list': 0.0959263, 'consideration': 0.09457592, 'statute': 0.09940287, 'help': 0.110094905}\n",
      "MAP value:  0.2857\n",
      "\n",
      "----------------- Running query 362 and human smuggling -----------------\n",
      "-> {'sweet': 0.100027256, 'block': 0.100027256, 'intercepting': 0.10131669, 'fifth': 0.09862882}\n",
      "MAP value:  0.1168\n",
      "\n",
      "----------------- Running query 363 and transportation tunnel disasters -----------------\n",
      "-> {'span': 0.1042253, 'spawn': 0.09752565, 'gold': 0.10072341, 'agent': 0.09752565}\n",
      "MAP value:  0.0125\n",
      "\n",
      "----------------- Running query 364 and rabies -----------------\n",
      "-> {'rapidly': 0.09965878, 'criteria': 0.097112685, 'control': 0.111328, 'inadequate': 0.09190051}\n",
      "MAP value:  0.1423\n",
      "\n",
      "----------------- Running query 365 and el nino -----------------\n",
      "-> {'people': 0.10179589, 'institution': 0.09936479, 'equator': 0.09936479, 'taking': 0.09947454}\n",
      "MAP value:  0.2571\n",
      "\n",
      "----------------- Running query 366 and commercial cyanide uses -----------------\n",
      "-> {'banning': 0.10050762, 'economics': 0.099282935, 'withdrawal': 0.102066316, 'ammonia': 0.098143145}\n",
      "MAP value:  0.0663\n",
      "\n",
      "Loss for epoch=0 and batch=1 : 0.186737060546875\n",
      "----------------- Running query 367 and piracy -----------------\n",
      "-> {'encouraging': 0.1054179, 'deterrent': 0.09699241, 'spread': 0.09699241, 'prevent': 0.100597315}\n",
      "MAP value:  0.0051\n",
      "\n",
      "----------------- Running query 368 and in vitro fertilization -----------------\n",
      "-> {'material': 0.11720117, 'parenthood': 0.08908709, 'offer': 0.09847932, 'late': 0.09523243}\n",
      "MAP value:  0.1639\n",
      "\n",
      "----------------- Running query 369 and anorexia nervosa bulimia -----------------\n",
      "-> {'intimate': 0.10160662, 'return': 0.0995728, 'fire': 0.1007455, 'intelligence': 0.0980751}\n",
      "MAP value:  0.1923\n",
      "\n",
      "----------------- Running query 370 and food drug laws -----------------\n",
      "-> {'judicial': 0.098534614, 'mutually': 0.093163244, 'affect': 0.096315645, 'accordance': 0.111986496}\n",
      "MAP value:  0.0015\n",
      "\n",
      "----------------- Running query 371 and health insurance holistic -----------------\n",
      "-> {'minded': 0.09332938, 'gym': 0.111700974, 'trustworthy': 0.10064788, 'interior': 0.09432175}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 372 and native american casino -----------------\n",
      "-> {'civilization': 0.0991117, 'press': 0.09732435, 'days': 0.10433201, 'martin': 0.09923195}\n",
      "MAP value:  0.0408\n",
      "\n",
      "----------------- Running query 373 and encryption equipment export -----------------\n",
      "-> {'ideal': 0.09685565, 'determination': 0.109993, 'notify': 0.09880578, 'social': 0.09434557}\n",
      "MAP value:  0.1578\n",
      "\n",
      "----------------- Running query 374 and nobel prize winners -----------------\n",
      "-> {'noted': 0.09554797, 'kill': 0.10255076, 'program': 0.10095065, 'kirsch': 0.10095065}\n",
      "MAP value:  0.0112\n",
      "\n",
      "----------------- Running query 375 and hydrogen energy -----------------\n",
      "-> {'conjunction': 0.09660386, 'concrete': 0.107385576, 'section': 0.094433144, 'spite': 0.10157742}\n",
      "MAP value:  0.0620\n",
      "\n",
      "----------------- Running query 376 and world court -----------------\n",
      "-> {'moreover': 0.10495728, 'superior': 0.08439991, 'ability': 0.10290032, 'verdict': 0.10774249}\n",
      "MAP value:  0.0098\n",
      "\n",
      "----------------- Running query 377 and cigar smoking -----------------\n",
      "-> {'notion': 0.082372405, 'nonsmoking': 0.10769142, 'adequately': 0.07971464, 'enjoy': 0.13022155}\n",
      "MAP value:  0.0755\n",
      "\n",
      "----------------- Running query 378 and euro opposition -----------------\n",
      "-> {'day': 0.07713017, 'attempt': 0.10710986, 'impair': 0.106998324, 'analyst': 0.10876167}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 379 and mainstreaming -----------------\n",
      "-> {'urge': 0.10080351, 'odd': 0.10486191, 'cent': 0.098731704, 'entrepreneurship': 0.095602885}\n",
      "MAP value:  0.2531\n",
      "\n",
      "----------------- Running query 380 and obesity medical treatment -----------------\n",
      "-> {'direction': 0.09853079, 'sophisticated': 0.10440823, 'committee': 0.09129788, 'plenty': 0.10576313}\n",
      "MAP value:  0.0952\n",
      "\n",
      "----------------- Running query 381 and alternative medicine -----------------\n",
      "-> {'simply': 0.1319475, 'equipment': 0.08445492, 'julio': 0.0943414, 'frightening': 0.089256175}\n",
      "MAP value:  0.0459\n",
      "\n",
      "----------------- Running query 382 and hydrogen fuel automobiles -----------------\n",
      "-> {'battery': 0.099681936, 'delivery': 0.10131391, 'van': 0.10063056, 'practicability': 0.098373584}\n",
      "MAP value:  0.1035\n",
      "\n",
      "----------------- Running query 383 and mental illness drugs -----------------\n",
      "-> {'series': 0.122912124, 'inspection': 0.09155592, 'narrowly': 0.09316954, 'comprehensive': 0.092362404}\n",
      "MAP value:  0.0086\n",
      "\n",
      "----------------- Running query 384 and space station moon -----------------\n",
      "-> {'imminent': 0.09583928, 'labor': 0.10229548, 'liquid': 0.10535661, 'involve': 0.096508645}\n",
      "MAP value:  0.0552\n",
      "\n",
      "----------------- Running query 385 and hybrid fuel cars -----------------\n",
      "-> {'reformer': 0.09712034, 'development': 0.10047752, 'approach': 0.100489035, 'declined': 0.10191311}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP value:  0.0697\n",
      "\n",
      "----------------- Running query 386 and teaching disabled children -----------------\n",
      "-> {'cerebral': 0.097916014, 'sad': 0.10254767, 'trash': 0.10528945, 'interpret': 0.09424688}\n",
      "MAP value:  0.0219\n",
      "\n",
      "----------------- Running query 387 and radioactive waste -----------------\n",
      "-> {'major': 0.092888825, 'laboratory': 0.09313186, 'select': 0.10347169, 'cesium': 0.11050763}\n",
      "MAP value:  0.0229\n",
      "\n",
      "----------------- Running query 388 and organic soil enhancement -----------------\n",
      "-> {'innovative': 0.12762044, 'retention': 0.10287448, 'poor': 0.098961174, 'equivalent': 0.070543885}\n",
      "MAP value:  0.0121\n",
      "\n",
      "----------------- Running query 389 and illegal technology transfer -----------------\n",
      "-> {'unavoidable': 0.10026007, 'legal': 0.3104449, 'charge': 0.09681601, 'usually': 0.09247905}\n",
      "MAP value:  0.0010\n",
      "\n",
      "----------------- Running query 390 and orphan drugs -----------------\n",
      "-> {'handful': 0.096889704, 'suffer': 0.09430707, 'efficiency': 0.100425616, 'manufacture': 0.10837761}\n",
      "MAP value:  0.0664\n",
      "\n",
      "----------------- Running query 391 and rd drug prices -----------------\n",
      "-> {'veterinary': 0.09852152, 'received': 0.10589101, 'safety': 0.09063824, 'provide': 0.10494923}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 392 and robotics -----------------\n",
      "-> {'million': 0.09883387, 'electronic': 0.09811267, 'painting': 0.10018011, 'swiss': 0.102873325}\n",
      "MAP value:  0.0254\n",
      "\n",
      "----------------- Running query 393 and mercy killing -----------------\n",
      "-> {'mind': 0.09701758, 'coercion': 0.10033796, 'sense': 0.10230648, 'condemned': 0.10033796}\n",
      "MAP value:  0.0744\n",
      "\n",
      "----------------- Running query 394 and home schooling -----------------\n",
      "-> {'director': 0.10580406, 'nor': 0.09108015, 'residual': 0.09713622, 'demand': 0.10597956}\n",
      "MAP value:  0.0756\n",
      "\n",
      "----------------- Running query 395 and tourism -----------------\n",
      "-> {'credit': 0.09025692, 'standing': 0.094887346, 'musical': 0.11960697, 'rated': 0.09524874}\n",
      "MAP value:  0.0035\n",
      "\n",
      "----------------- Running query 396 and sick building syndrome -----------------\n",
      "-> {'appear': 0.101570606, 'feeding': 0.09982326, 'sinus': 0.09778782, 'temporal': 0.10081836}\n",
      "MAP value:  0.1695\n",
      "\n",
      "----------------- Running query 397 and automobile recalls -----------------\n",
      "-> {'factor': 0.10028849, 'organizer': 0.09940229, 'social': 0.10090696, 'exploring': 0.09940229}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 398 and dismantling europe arsenal -----------------\n",
      "-> {'despite': 0.088373594, 'concerned': 0.11060752, 'proliferation': 0.09041136, 'assumed': 0.11060752}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 399 and oceanographic vessels -----------------\n",
      "-> {'repair': 0.10206395, 'deal': 0.10206395, 'principally': 0.10170429, 'public': 0.094167836}\n",
      "MAP value:  0.0041\n",
      "\n",
      "----------------- Running query 400 and amazon rain forest -----------------\n",
      "-> {'department': 0.098681524, 'reach': 0.09512789, 'classified': 0.0959621, 'research': 0.11022848}\n",
      "MAP value:  0.0712\n",
      "\n",
      "----------------- Running query 401 and foreign minorities germany -----------------\n",
      "-> {'mutual': 0.09815968, 'unlikely': 0.09984821, 'influence': 0.09866591, 'original': 0.1033262}\n",
      "MAP value:  0.0047\n",
      "\n",
      "----------------- Running query 402 and behavioral genetics -----------------\n",
      "-> {'susceptible': 0.10251826, 'paint': 0.10083512, 'result': 0.09287604, 'blame': 0.10377057}\n",
      "MAP value:  0.0125\n",
      "\n",
      "----------------- Running query 403 and osteoporosis -----------------\n",
      "-> {'lucrative': 0.098120354, 'council': 0.09562781, 'population': 0.103297174, 'considerable': 0.10295468}\n",
      "MAP value:  0.4058\n",
      "\n",
      "----------------- Running query 404 and ireland peace talks -----------------\n",
      "-> {'validly': 0.09055772, 'bereavement': 0.10207011, 'word': 0.10556232, 'progress': 0.10180985}\n",
      "MAP value:  0.0038\n",
      "\n",
      "----------------- Running query 405 and cosmic events -----------------\n",
      "-> {'watching': 0.09509938, 'destruction': 0.10325122, 'exactly': 0.10082471, 'cheap': 0.10082471}\n",
      "MAP value:  0.0306\n",
      "\n",
      "----------------- Running query 406 and parkinson disease -----------------\n",
      "-> {'temerity': 0.09705552, 'walled': 0.100531064, 'neurology': 0.09966843, 'fit': 0.102745}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 407 and poaching wildlife preserves -----------------\n",
      "-> {'fishing': 0.12036886, 'effective': 0.10430616, 'five': 0.09895741, 'thin': 0.07636755}\n",
      "MAP value:  0.0783\n",
      "\n",
      "----------------- Running query 408 and tropical storms -----------------\n",
      "-> {'am': 0.09752506, 'oxygen': 0.10355914, 'acting': 0.09953802, 'theres': 0.09937778}\n",
      "MAP value:  0.0254\n",
      "\n",
      "----------------- Running query 409 and legal pan am 103 -----------------\n",
      "-> {'phony': 0.103218295, 'administrator': 0.10199477, 'terrorism': 0.083206154, 'victim': 0.11158079}\n",
      "MAP value:  0.0455\n",
      "\n",
      "----------------- Running query 410 and schengen agreement -----------------\n",
      "-> {'exercise': 0.09616374, 'readiness': 0.10088096, 'consequently': 0.10679155, 'scandal': 0.09616374}\n",
      "MAP value:  0.1538\n",
      "\n",
      "----------------- Running query 411 and salvaging shipwreck treasure -----------------\n",
      "-> {'writer': 0.09955215, 'approaching': 0.09239808, 'income': 0.09663932, 'five': 0.111410476}\n",
      "MAP value:  0.1111\n",
      "\n",
      "----------------- Running query 412 and airport security -----------------\n",
      "-> {'screen': 0.10082723, 'bomb': 0.10192148, 'bit': 0.101146355, 'explosion': 0.09610494}\n",
      "MAP value:  0.0227\n",
      "\n",
      "----------------- Running query 413 and steel production -----------------\n",
      "-> {'transferring': 0.10652276, 'engine': 0.08858829, 'quality': 0.11169113, 'axed': 0.093197815}\n",
      "MAP value:  0.0420\n",
      "\n",
      "----------------- Running query 414 and cuba sugar exports -----------------\n",
      "-> {'oil': 0.1023106, 'directly': 0.11435205, 'future': 0.096200064, 'stop': 0.087137334}\n",
      "MAP value:  0.0705\n",
      "\n",
      "----------------- Running query 415 and drugs golden triangle -----------------\n",
      "-> {'preferred': 0.095437825, 'lead': 0.095437825, 'scored': 0.10315279, 'tripartite': 0.10597155}\n",
      "MAP value:  0.0574\n",
      "\n",
      "----------------- Running query 416 and three gorges project -----------------\n",
      "-> {'transmission': 0.09511467, 'communism': 0.10148394, 'sharply': 0.101700686, 'intact': 0.101700686}\n",
      "MAP value:  0.0658\n",
      "\n",
      "----------------- Running query 417 and creativity -----------------\n",
      "-> {'smoothly': 0.09037404, 'sampling': 0.13124071, 'national': 0.08801122, 'stage': 0.09037404}\n",
      "MAP value:  0.0933\n",
      "\n",
      "----------------- Running query 418 and quilts income -----------------\n",
      "-> {'standish': 0.10201073, 'hard': 0.09805962, 'classic': 0.10193584, 'surprising': 0.09799382}\n",
      "MAP value:  0.0558\n",
      "\n",
      "----------------- Running query 419 and recycle automobile tires -----------------\n",
      "-> {'march': 0.096171565, 'process': 0.09595278, 'sparking': 0.11474021, 'coke': 0.09313546}\n",
      "MAP value:  0.0833\n",
      "\n",
      "----------------- Running query 420 and carbon monoxide poisoning -----------------\n",
      "-> {'provided': 0.10307207, 'lantern': 0.103037, 'apocalyptic': 0.091381334, 'president': 0.102509595}\n",
      "MAP value:  0.2663\n",
      "\n",
      "----------------- Running query 421 and industrial waste disposal -----------------\n",
      "-> {'moving': 0.10528745, 'tracing': 0.10528745, 'dredge': 0.10041248, 'shaw': 0.08901262}\n",
      "MAP value:  0.0084\n",
      "\n",
      "----------------- Running query 422 and art stolen forged -----------------\n",
      "-> {'deliberately': 0.08456164, 'build': 0.08480632, 'truck': 0.13077033, 'carry': 0.09986173}\n",
      "MAP value:  0.0138\n",
      "\n",
      "----------------- Running query 423 and milosevic mirjana markovic -----------------\n",
      "-> {'conviction': 0.09721998, 'pure': 0.096405014, 'apparently': 0.08985214, 'course': 0.11652287}\n",
      "MAP value:  0.3883\n",
      "\n",
      "----------------- Running query 425 and counterfeiting money -----------------\n",
      "-> {'organ': 0.09893414, 'whom': 0.10107925, 'storehouse': 0.10308162, 'chrysanthemum': 0.09690501}\n",
      "MAP value:  0.0549\n",
      "\n",
      "----------------- Running query 426 and law enforcement dogs -----------------\n",
      "-> {'feared': 0.10202717, 'drove': 0.1025092, 'objectivity': 0.093436465, 'none': 0.10202717}\n",
      "MAP value:  0.0162\n",
      "\n",
      "----------------- Running query 427 and uv damage eyes -----------------\n",
      "-> {'flicker': 0.11000768, 'warning': 0.07692381, 'augmentation': 0.11370025, 'glass': 0.09936824}\n",
      "MAP value:  0.0605\n",
      "\n",
      "----------------- Running query 428 and declining birth rates -----------------\n",
      "-> {'temporary': 0.11368602, 'south': 0.08680595, 'logistical': 0.109750025, 'difference': 0.08975804}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP value:  0.0264\n",
      "\n",
      "----------------- Running query 429 and legionnaires disease -----------------\n",
      "-> {'dioxide': 0.08968937, 'aspergillus': 0.08977741, 'filtration': 0.08977741, 'lung': 0.13075581}\n",
      "MAP value:  0.0485\n",
      "\n",
      "----------------- Running query 430 and killer bee attacks -----------------\n",
      "-> {'cantaloupe': 0.10148268, 'pacific': 0.09960806, 'finding': 0.106100954, 'port': 0.09280831}\n",
      "MAP value:  0.4907\n",
      "\n",
      "----------------- Running query 431 and robotic technology -----------------\n",
      "-> {'available': 0.104579665, 'prompt': 0.09368877, 'determine': 0.098625325, 'erosion': 0.10310625}\n",
      "MAP value:  0.0218\n",
      "\n",
      "Loss for epoch=0 and batch=2 : -1.269749402999878\n",
      "----------------- Running query 432 and profiling motorists police -----------------\n",
      "-> {'colin': 0.09965232, 'relate': 0.102752104, 'highlight': 0.09965232, 'chemical': 0.09794326}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 433 and greek philosophy stoicism -----------------\n",
      "-> {'technocratic': 0.09437702, 'landing': 0.100460924, 'chapter': 0.102581024, 'shopping': 0.102581024}\n",
      "MAP value:  0.0641\n",
      "\n",
      "----------------- Running query 434 and estonia economy -----------------\n",
      "-> {'chamber': 0.100147806, 'radiate': 0.09985218, 'metal': 0.09985218, 'secondary': 0.100147806}\n",
      "MAP value:  0.0180\n",
      "\n",
      "----------------- Running query 435 and curbing population growth -----------------\n",
      "-> {'consumer': 0.09259851, 'june': 0.10381023, 'dairy': 0.099781066, 'vying': 0.10381023}\n",
      "MAP value:  0.0171\n",
      "\n",
      "Loss for epoch=0 and batch=rem : -0.0008364287205040455\n",
      "Start of training epoch : 1\n",
      "----------------- Running query 301 and international organized crime -----------------\n",
      "-> {'record': 0.10178864, 'whenever': 0.09973714, 'qualitative': 0.09855862, 'tula': 0.09991559}\n",
      "MAP value:  0.0049\n",
      "\n",
      "----------------- Running query 302 and poliomyelitis post polio -----------------\n",
      "-> {'mastery': 0.10054721, 'narcissi': 0.10054721, 'employ': 0.10054721, 'action': 0.09835841}\n",
      "MAP value:  0.0871\n",
      "\n",
      "----------------- Running query 303 and hubble telescope achievements -----------------\n",
      "-> {'nonetheless': 0.10609424, 'costing': 0.1109473, 'built': 0.076864235, 'intervention': 0.10609424}\n",
      "MAP value:  0.1000\n",
      "\n",
      "----------------- Running query 304 and endangered species mammals -----------------\n",
      "-> {'geographically': 0.09131215, 'turkey': 0.085125685, 'section': 0.13565402, 'education': 0.087908186}\n",
      "MAP value:  0.0071\n",
      "\n",
      "----------------- Running query 305 and most dangerous vehicles -----------------\n",
      "-> {'suddenly': 0.090063564, 'crossed': 0.10874202, 'gross': 0.09876587, 'degree': 0.10242855}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 306 and african civilian deaths -----------------\n",
      "-> {'administration': 0.09394893, 'violent': 0.0980068, 'execution': 0.10937375, 'peak': 0.0986705}\n",
      "MAP value:  0.0023\n",
      "\n",
      "----------------- Running query 307 and new hydroelectric projects -----------------\n",
      "-> {'crop': 0.10030662, 'mineral': 0.09891398, 'forecast': 0.1003897, 'expedited': 0.1003897}\n",
      "MAP value:  0.0293\n",
      "\n",
      "----------------- Running query 308 and implant dentistry -----------------\n",
      "-> {'current': 0.09551399, 'identification': 0.106028534, 'directional': 0.09225007, 'multinucleated': 0.10620742}\n",
      "MAP value:  0.5000\n",
      "\n",
      "----------------- Running query 309 and rap and crime -----------------\n",
      "-> {'seven': 0.094534494, 'snap': 0.09913784, 'filled': 0.1005479, 'support': 0.10577973}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 310 and radio waves and brain cancer -----------------\n",
      "-> {'quick': 0.09698471, 'assessment': 0.105025075, 'absorbed': 0.09131455, 'building': 0.106675625}\n",
      "MAP value:  0.1077\n",
      "\n",
      "----------------- Running query 311 and industrial espionage -----------------\n",
      "-> {'spent': 0.10414249, 'value': 0.09621364, 'setting': 0.09344217, 'criminal': 0.10620172}\n",
      "MAP value:  0.0448\n",
      "\n",
      "----------------- Running query 313 and magnetic levitation maglev -----------------\n",
      "-> {'passing': 0.095646404, 'wine': 0.102226846, 'helpful': 0.10283589, 'super': 0.09929086}\n",
      "MAP value:  0.1075\n",
      "\n",
      "----------------- Running query 314 and marine vegetation -----------------\n",
      "-> {'solid': 0.09524124, 'silverspot': 0.0974217, 'begin': 0.10801654, 'aide': 0.09932051}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 315 and unexplained highway accidents -----------------\n",
      "-> {'petrol': 0.09963294, 'try': 0.10141688, 'el': 0.10429472, 'ideally': 0.09465548}\n",
      "MAP value:  0.0000\n",
      "\n",
      "----------------- Running query 316 and polygamy polyandry polygyny -----------------\n",
      "-> {'ostensibly': 0.10004445, 'prevention': 0.10186958, 'expend': 0.09904298, 'cutting': 0.09904298}\n",
      "MAP value:  0.1426\n",
      "\n",
      "----------------- Running query 317 and unsolicited faxes -----------------\n",
      "-> {'mismatch': 0.08527744, 'community': 0.08249196, 'data': 0.1272507, 'hardware': 0.104979895}\n",
      "MAP value:  0.0873\n",
      "\n",
      "----------------- Running query 318 and best retirement country -----------------\n",
      "-> {'sustainable': 0.10114763, 'interrupted': 0.09979928, 'theres': 0.10258184, 'lonesome': 0.096471295}\n",
      "MAP value:  0.0094\n",
      "\n",
      "----------------- Running query 319 and new fuel sources -----------------\n",
      "-> {'objective': 0.10167863, 'ward': 0.102157, 'union': 0.10128792, 'hereafter': 0.09487647}\n",
      "MAP value:  0.0131\n",
      "\n",
      "----------------- Running query 320 and undersea fiber optic cable -----------------\n",
      "-> {'adoption': 0.096021995, 'immediately': 0.100821845, 'gains': 0.096021995, 'west': 0.10713416}\n",
      "MAP value:  0.0238\n",
      "\n",
      "----------------- Running query 321 and women in parliaments -----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3e564d231612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_docs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# comment this statement to train the model from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_query_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_doc_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time elapsed in training the model : {} hrs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-01ba76d22307>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, query_df, query_doc_dict, epochs, batch_size)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# X_batch is a dataframe with 'index' and 'query' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss for epoch={} and batch={} : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mgradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-01ba76d22307>\u001b[0m in \u001b[0;36mcompute_loss_fn\u001b[0;34m(self, X_batch)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_doc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;31m# stores words used in the top 'num_of_docs' retrieved by a single query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_dist_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mword_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR_dash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mR_MLE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_MLE_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-01ba76d22307>\u001b[0m in \u001b[0;36mprob_dist_query\u001b[0;34m(self, F)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprob_dist_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ---> R(Q,F;C,Omega)   F has shape : (num_of_words,num_of_docs,num_of_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m \u001b[0;31m# returns array of softmax p(w/Q) -- shape(num_of_words,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fc33e5d4db5c>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, training)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mcomp_inp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomp_inp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2fecb6bfcdc7>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#            )]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_len_dectobin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtemp_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0magg_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f56ba4baa20e>\u001b[0m in \u001b[0;36mfixed_len_dectobin\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mmax_binary_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfinal_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   7052\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7053\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7054\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7055\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7056\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;34m\"strided_slice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m       skip_on_eager=False) as name:\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6719\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6720\u001b[0m         \u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6721\u001b[0;31m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6723\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_restore_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvp3/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mscope_name\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;34m\"\"\"Sets scope name for the current thread.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# execute this cell to train the model.\n",
    "# Takes input the list of queries as query_df and the documents retrieved by each query as query_doc_dict\n",
    "start=time.time()\n",
    "rml=RML_model(4) # pass K : the number of samples to extract for query reformulation\n",
    "x = train_doc_dict[train_query_df.iloc[0]['index']]\n",
    "temp = rml.model(tf.random.uniform(shape=[x.shape[0],num_of_docs,num_of_features]),training=False)\n",
    "rml.model.load_weights('saved_weights.h5') # comment this statement to train the model from scratch\n",
    "rml.train(train_query_df,train_doc_dict,epochs = 2, batch_size = 64)\n",
    "end=time.time()\n",
    "print('time elapsed in training the model : {} hrs'.format((end-start)/3600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "014557a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights of the model\n",
    "rml.model.save_weights('saved_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94710e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'policy__network__model/policy__net__block/phi__block/w_phi:0' shape=(20,) dtype=float32, numpy=\n",
       "array([0.30985805, 0.88752383, 0.269065  , 0.55500835, 0.7633393 ,\n",
       "       0.62908787, 0.92710507, 0.2243061 , 0.54521054, 0.30970347,\n",
       "       0.65288955, 0.64080924, 0.573331  , 0.2765277 , 0.9137944 ,\n",
       "       0.22049949, 0.06107275, 0.41391474, 0.7974824 , 0.98787355],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rml.model.trainable_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b31c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model : \n",
      "query : railway accidents\n",
      "Reformalised query terms -> {'labor': 0.13254432, 'reform': 0.10496382, 'drug': 0.08551115, 'yuan': 0.07698074}\n",
      "MAP value:  0.0000\n",
      "\n",
      "query : deregulation gas electric\n",
      "Reformalised query terms -> {'company': 0.121422306, 'electric': 0.29850376, 'increase': 0.09016055, 'people': 0.08991339}\n",
      "MAP value:  0.0000\n",
      "\n",
      "query : tourism increase\n",
      "Reformalised query terms -> {'percent': 0.11094677, 'office': 0.096856326, 'current': 0.09631947, 'change': 0.09587746}\n",
      "MAP value:  0.0024\n",
      "\n",
      "query : inventions scientific discoveries\n",
      "Reformalised query terms -> {'world': 0.109131746, 'share': 0.09847072, 'task': 0.096212566, 'program': 0.096185}\n",
      "MAP value:  0.0000\n",
      "\n",
      "query : child labor\n",
      "Reformalised query terms -> {'day': 0.10649319, 'outside': 0.10297185, 'school': 0.09563116, 'employment': 0.09490382}\n",
      "MAP value:  0.0060\n",
      "\n",
      "query : lyme disease\n",
      "Reformalised query terms -> {'tick': 0.14465557, 'p': 0.09061281, 'di': 0.38284105, 'fever': 0.08189063}\n",
      "MAP value:  0.3113\n",
      "\n",
      "query : heroic acts\n",
      "Reformalised query terms -> {'text': 0.14038868, 'people': 0.10085952, 'yesterday': 0.07937591, 'supporting': 0.07937591}\n",
      "MAP value:  0.0000\n",
      "\n",
      "query : united states investment africa\n",
      "Reformalised query terms -> {'foreign': 0.1053396, 'economic': 0.10155689, 'south': 0.09757494, 'bank': 0.095528565}\n",
      "MAP value:  0.0114\n",
      "\n",
      "query : supercritical fluids\n",
      "Reformalised query terms -> {'supercritical': 0.42064497, 'plastic': 0.093690924, 'research': 0.093678586, 'porous': 0.091985576}\n",
      "MAP value:  0.5235\n",
      "\n",
      "query : women clergy\n",
      "Reformalised query terms -> {'p': 0.10511392, 'priesthood': 0.09886073, 'ordination': 0.09880227, 'leave': 0.097223066}\n",
      "MAP value:  0.1202\n",
      "\n",
      "query : tourists violence\n",
      "Reformalised query terms -> {'tourist': 0.4100613, 'cent': 0.09789524, 'recent': 0.09626598, 'time': 0.095777474}\n",
      "MAP value:  0.0427\n",
      "\n",
      "query : stirling engine\n",
      "Reformalised query terms -> {'engineering': 0.10067705, 'fuel': 0.100574724, 'testing': 0.10003101, 'public': 0.098717205}\n",
      "MAP value:  0.1510\n",
      "\n",
      "query : ship losses\n",
      "Reformalised query terms -> {'application': 0.1064842, 'result': 0.10115576, 'time': 0.09811049, 'office': 0.09424957}\n",
      "MAP value:  0.0031\n",
      "\n",
      "query : antibiotics ineffectiveness\n",
      "Reformalised query terms -> {'bacterium': 0.1041669, 'associated': 0.10032325, 'action': 0.0982175, 'currently': 0.097292356}\n",
      "MAP value:  0.0137\n",
      "\n",
      "query : king hussein peace\n",
      "Reformalised query terms -> {'political': 0.1076917, 'gulf': 0.102717556, 'economy': 0.09797155, 'peace': 0.29161924}\n",
      "MAP value:  0.0209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validaton \n",
    "MAP_score = rml.test(test_query_df,test_doc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5682163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08041334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(MAP_score).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf0d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 26 14:26:19 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K40c          On   | 00000000:04:00.0 Off |                    0 |\r\n",
      "| 23%   33C    P8    23W / 235W |     11MiB / 11441MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855883e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
